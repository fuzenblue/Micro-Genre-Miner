import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import numpy as np
from collections import Counter
import re

st.title("ЁЯУИ Trends тАФ р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Ар╕Чр╕гр╕Щр╕Фр╣Мр╣Ар╕Кр╕┤р╕Зр╕ер╕╢р╕Б")

@st.cache_data
def load_data():
    return pd.read_parquet("movie_clusters_keybert.parquet")

df = load_data()

# Ensure we have year data
if 'year' not in df.columns:
    st.error("р╣Др╕бр╣Ир╕Юр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ыр╕╡р╣Гр╕Щр╕Рр╕▓р╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕е")
    st.stop()

st.markdown("---")

# 1. Time-Series Analysis
st.markdown("## ЁЯУК 1. р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Хр╕▓р╕бр╕Бр╕▓р╕ер╣Ар╕зр╕ер╕▓")

st.markdown("### ЁЯОм The Rise and Fall of Micro-Genres")

# Get individual genres (split by /)
all_genres = []
for genre_str in df['micro_genre_keybert'].dropna():
    genres = [g.strip() for g in str(genre_str).split('/')]
    all_genres.extend(genres)

top_genres = pd.Series(all_genres).value_counts().head(15).index.tolist()

# Multi-select for genre comparison
selected_genres = st.multiselect(
    "р╣Ар╕ер╕╖р╕нр╕Б Micro-Genres р╕Чр╕╡р╣Ир╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕гр╣Ар╕Ыр╕гр╕╡р╕вр╕Ър╣Ар╕Чр╕╡р╕вр╕Ъ (р╕кр╕╣р╕Зр╕кр╕╕р╕Ф 5 р╕Бр╕ер╕╕р╣Ир╕б):",
    options=top_genres,
    default=top_genres[:3],
    max_selections=5,
    help="р╣Ар╕ер╕╖р╕нр╕Бр╕Бр╕ер╕╕р╣Ир╕бр╕Чр╕╡р╣Ир╕кр╕Щр╣Гр╕Ир╣Ар╕Юр╕╖р╣Ир╕нр╕Фр╕╣р╣Ар╕Чр╕гр╕Щр╕Фр╣Мр╕Бр╕▓р╕гр╣Ар╕Ыр╕ер╕╡р╣Ир╕вр╕Щр╣Бр╕Ыр╕ер╕Зр╕Хр╕▓р╕бр╣Ар╕зр╕ер╕▓"
)

if selected_genres:
    # Create time series data
    time_series_data = []
    
    for genre in selected_genres:
        genre_df = df[df['micro_genre_keybert'].str.contains(genre, case=False, na=False)]
        yearly_counts = genre_df.groupby('year').size().reset_index(name='count')
        yearly_counts['genre'] = genre
        time_series_data.append(yearly_counts)
    
    combined_data = pd.concat(time_series_data, ignore_index=True)
    
    # Create multi-line chart
    fig_timeline = px.line(
        combined_data,
        x='year',
        y='count',
        color='genre',
        title="р╕Ир╕│р╕Щр╕зр╕Щр╕лр╕Щр╕▒р╕Зр╕Чр╕╡р╣Ир╕Ьр╕ер╕┤р╕Хр╣Гр╕Щр╣Бр╕Хр╣Ир╕ер╕░р╕Ыр╕╡",
        labels={'year': 'р╕Ыр╕╡', 'count': 'р╕Ир╕│р╕Щр╕зр╕Щр╕лр╕Щр╕▒р╕З', 'genre': 'Micro-Genre'},
        markers=True
    )
    
    fig_timeline.update_layout(
        height=500,
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    st.plotly_chart(fig_timeline, use_container_width=True)
    
    # Insights
    st.info("""
    ЁЯТб **Insight:** р╣Ар╕кр╣Йр╕Щр╕Бр╕гр╕▓р╕Яр╣Бр╕кр╕Фр╕Зр╣Гр╕лр╣Йр╣Ар╕лр╣Зр╕Щр╕Бр╕▓р╕гр╣Ар╕Ыр╕ер╕╡р╣Ир╕вр╕Щр╣Бр╕Ыр╕ер╕Зр╕Др╕зр╕▓р╕бр╕Щр╕┤р╕вр╕бр╕Вр╕нр╕Зр╣Бр╕Хр╣Ир╕ер╕░ Micro-Genre р╕Хр╕▓р╕бр╕вр╕╕р╕Др╕кр╕бр╕▒р╕в 
    р╣Ар╕Кр╣Ир╕Щ р╕лр╕Щр╕▒р╕З Superhero р╕нр╕▓р╕Ир╕Юр╕╕р╣Ир╕Зр╕кр╕╣р╕Зр╣Гр╕Щр╕Кр╣Ир╕зр╕З 2010s р╕лр╕гр╕╖р╕н Horror Slasher р╣Др╕Фр╣Йр╕гр╕▒р╕Ър╕Др╕зр╕▓р╕бр╕Щр╕┤р╕вр╕бр╣Гр╕Щр╕вр╕╕р╕Д 80s
    """)

# Heatmap Calendar
st.markdown("### ЁЯЧУя╕П р╕Др╕зр╕▓р╕бр╕лр╕Щр╕▓р╣Бр╕Щр╣Ир╕Щр╕Бр╕▓р╕гр╕Ьр╕ер╕┤р╕Хр╕лр╕Щр╕▒р╕Зр╕Хр╕▓р╕бр╕Ыр╕╡")

# Create decade-based heatmap
df_heatmap = df.copy()
df_heatmap['decade'] = (df_heatmap['year'] // 10) * 10

# Get top 10 genres for heatmap
top_10_genres = df['micro_genre_keybert'].value_counts().head(10).index

heatmap_data = df_heatmap[df_heatmap['micro_genre_keybert'].isin(top_10_genres)]
heatmap_pivot = heatmap_data.groupby(['decade', 'micro_genre_keybert']).size().unstack(fill_value=0)

fig_heatmap = px.imshow(
    heatmap_pivot.T,
    title="р╕Др╕зр╕▓р╕бр╕лр╕Щр╕▓р╣Бр╕Щр╣Ир╕Щр╕Вр╕нр╕З Micro-Genres р╣Гр╕Щр╣Бр╕Хр╣Ир╕ер╕░р╕Чр╕ир╕зр╕гр╕гр╕й",
    labels={'x': 'р╕Чр╕ир╕зр╕гр╕гр╕й', 'y': 'Micro-Genre', 'color': 'р╕Ир╕│р╕Щр╕зр╕Щр╕лр╕Щр╕▒р╕З'},
    aspect='auto',
    color_continuous_scale='YlOrRd'
)

fig_heatmap.update_layout(height=400)
st.plotly_chart(fig_heatmap, use_container_width=True)

st.markdown("---")

# 2. Semantic Analysis
st.markdown("## тШБя╕П 2. р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕в (Semantic Analysis)")

st.markdown("### ЁЯФд Dynamic Word Cloud")

# Genre selection for word cloud
selected_genre_wc = st.selectbox(
    "р╣Ар╕ер╕╖р╕нр╕Б Micro-Genre р╣Ар╕Юр╕╖р╣Ир╕нр╕Фр╕╣ Word Cloud:",
    options=top_genres,
    help="р╣Ар╕ер╕╖р╕нр╕Бр╕Бр╕ер╕╕р╣Ир╕бр╕Чр╕╡р╣Ир╕кр╕Щр╣Гр╕Ир╣Ар╕Юр╕╖р╣Ир╕нр╕Фр╕╣р╕Др╕│р╕кр╕│р╕Др╕▒р╕Нр╕Чр╕╡р╣Ир╕Ыр╕гр╕▓р╕Бр╕Пр╕Ър╣Ир╕нр╕вр╣Гр╕Щ Plot"
)

if selected_genre_wc:
    # Get movies from selected genre (contains the selected genre)
    genre_movies = df[df['micro_genre_keybert'].str.contains(selected_genre_wc, case=False, na=False)]
    
    # Create word cloud from overview/plot text if available
    if 'overview' in df.columns:
        # Combine all overviews from the selected genre
        text_data = ' '.join(genre_movies['overview'].dropna().astype(str))
        
        # Clean text (basic preprocessing)
        text_data = re.sub(r'[^\w\s]', ' ', text_data.lower())
        text_data = re.sub(r'\s+', ' ', text_data)
        
        # Enhanced stop words list
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them', 'his', 'their', 'one', 'two', 'three', 'who', 'what', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'just', 'now', 'get', 'gets', 'got', 'make', 'makes', 'made', 'take', 'takes', 'took', 'come', 'comes', 'came', 'go', 'goes', 'went', 'see', 'sees', 'saw', 'know', 'knows', 'knew', 'think', 'thinks', 'thought', 'say', 'says', 'said', 'tell', 'tells', 'told', 'ask', 'asks', 'asked', 'work', 'works', 'worked', 'seem', 'seems', 'seemed', 'feel', 'feels', 'felt', 'try', 'tries', 'tried', 'leave', 'leaves', 'left', 'put', 'puts', 'end', 'ends', 'ended', 'find', 'finds', 'found', 'give', 'gives', 'gave', 'turn', 'turns', 'turned', 'start', 'starts', 'started', 'show', 'shows', 'showed', 'hear', 'hears', 'heard', 'play', 'plays', 'played', 'run', 'runs', 'ran', 'move', 'moves', 'moved', 'live', 'lives', 'lived', 'believe', 'believes', 'believed', 'hold', 'holds', 'held', 'bring', 'brings', 'brought', 'happen', 'happens', 'happened', 'write', 'writes', 'wrote', 'sit', 'sits', 'sat', 'stand', 'stands', 'stood', 'lose', 'loses', 'lost', 'pay', 'pays', 'paid', 'meet', 'meets', 'met', 'include', 'includes', 'included', 'continue', 'continues', 'continued', 'set', 'sets', 'follow', 'follows', 'followed', 'stop', 'stops', 'stopped', 'create', 'creates', 'created', 'speak', 'speaks', 'spoke', 'read', 'reads', 'allow', 'allows', 'allowed', 'add', 'adds', 'added', 'spend', 'spends', 'spent', 'grow', 'grows', 'grew', 'open', 'opens', 'opened', 'walk', 'walks', 'walked', 'win', 'wins', 'won', 'offer', 'offers', 'offered', 'remember', 'remembers', 'remembered', 'love', 'loves', 'loved', 'consider', 'considers', 'considered', 'appear', 'appears', 'appeared', 'buy', 'buys', 'bought', 'wait', 'waits', 'waited', 'serve', 'serves', 'served', 'die', 'dies', 'died', 'send', 'sends', 'sent', 'expect', 'expects', 'expected', 'build', 'builds', 'built', 'stay', 'stays', 'stayed', 'fall', 'falls', 'fell', 'cut', 'cuts', 'reach', 'reaches', 'reached', 'kill', 'kills', 'killed', 'remain', 'remains', 'remained', 'suggest', 'suggests', 'suggested', 'raise', 'raises', 'raised', 'pass', 'passes', 'passed', 'sell', 'sells', 'sold', 'require', 'requires', 'required', 'report', 'reports', 'reported', 'decide', 'decides', 'decided', 'pull', 'pulls', 'pulled', 'movie', 'film', 'cinema', 'story', 'character', 'plot', 'scene', 'director', 'actor', 'actress', 'cast', 'role', 'performance', 'drama', 'action', 'comedy', 'horror', 'thriller', 'romance', 'adventure', 'fantasy', 'fiction', 'documentary', 'animation', 'musical', 'western', 'crime', 'mystery', 'war', 'biography', 'history', 'family', 'sport', 'music', 'dance', 'art', 'culture', 'society', 'politics', 'religion', 'science', 'technology', 'nature', 'animal', 'human', 'man', 'woman', 'child', 'boy', 'girl', 'father', 'mother', 'son', 'daughter', 'brother', 'sister', 'friend', 'enemy', 'hero', 'villain', 'good', 'bad', 'evil', 'dark', 'light', 'black', 'white', 'red', 'blue', 'green', 'yellow', 'big', 'small', 'long', 'short', 'high', 'low', 'fast', 'slow', 'old', 'new', 'young', 'beautiful', 'ugly', 'strong', 'weak', 'rich', 'poor', 'happy', 'sad', 'angry', 'afraid', 'surprised', 'excited', 'bored', 'tired', 'hungry', 'thirsty', 'hot', 'cold', 'warm', 'cool', 'wet', 'dry', 'clean', 'dirty', 'easy', 'hard', 'simple', 'complex', 'clear', 'unclear', 'true', 'false', 'right', 'wrong', 'correct', 'incorrect', 'real', 'fake', 'natural', 'artificial', 'normal', 'strange', 'weird', 'funny', 'serious', 'important', 'unimportant', 'necessary', 'unnecessary', 'possible', 'impossible', 'probable', 'improbable', 'certain', 'uncertain', 'sure', 'unsure', 'safe', 'dangerous', 'risky', 'secure', 'insecure', 'public', 'private', 'personal', 'professional', 'official', 'unofficial', 'formal', 'informal', 'legal', 'illegal', 'moral', 'immoral', 'ethical', 'unethical', 'fair', 'unfair', 'equal', 'unequal', 'similar', 'different', 'same', 'opposite', 'near', 'far', 'close', 'distant', 'inside', 'outside', 'above', 'below', 'over', 'under', 'before', 'after', 'during', 'while', 'until', 'since', 'from', 'into', 'onto', 'off', 'out', 'up', 'down', 'left', 'right', 'north', 'south', 'east', 'west', 'here', 'there', 'everywhere', 'nowhere', 'somewhere', 'anywhere', 'always', 'never', 'sometimes', 'often', 'rarely', 'seldom', 'usually', 'normally', 'generally', 'specifically', 'particularly', 'especially', 'mainly', 'mostly', 'partly', 'completely', 'totally', 'fully', 'entirely', 'absolutely', 'relatively', 'approximately', 'exactly', 'precisely', 'roughly', 'about', 'around', 'nearly', 'almost', 'quite', 'rather', 'pretty', 'fairly', 'somewhat', 'slightly', 'barely', 'hardly', 'scarcely', 'extremely', 'very', 'really', 'truly', 'actually', 'indeed', 'certainly', 'definitely', 'probably', 'maybe', 'perhaps', 'possibly', 'likely', 'unlikely', 'obviously', 'clearly', 'apparently', 'seemingly', 'supposedly', 'allegedly', 'reportedly', 'according', 'based', 'depending', 'regarding', 'concerning', 'involving', 'including', 'excluding', 'except', 'besides', 'apart', 'aside', 'along', 'across', 'through', 'throughout', 'within', 'without', 'against', 'towards', 'between', 'among', 'amongst', 'beyond', 'beneath', 'beside', 'behind', 'ahead', 'forward', 'backward', 'upward', 'downward', 'inward', 'outward', 'toward', 'away', 'together', 'apart', 'alone', 'single', 'double', 'triple', 'multiple', 'several', 'many', 'much', 'little', 'less', 'least', 'more', 'most', 'enough', 'too', 'also', 'either', 'neither', 'both', 'all', 'none', 'some', 'any', 'every', 'each', 'another', 'other', 'others', 'else', 'otherwise', 'however', 'therefore', 'thus', 'hence', 'consequently', 'accordingly', 'meanwhile', 'nevertheless', 'nonetheless', 'furthermore', 'moreover', 'additionally', 'besides', 'instead', 'rather', 'alternatively', 'similarly', 'likewise', 'equally', 'comparatively', 'relatively', 'respectively', 'particularly', 'especially', 'specifically', 'generally', 'usually', 'normally', 'typically', 'commonly', 'frequently', 'regularly', 'occasionally', 'sometimes', 'rarely', 'seldom', 'never', 'always', 'constantly', 'continuously', 'permanently', 'temporarily', 'briefly', 'shortly', 'quickly', 'slowly', 'gradually', 'suddenly', 'immediately', 'instantly', 'eventually', 'finally', 'ultimately', 'originally', 'initially', 'firstly', 'secondly', 'thirdly', 'lastly', 'previously', 'formerly', 'recently', 'currently', 'presently', 'nowadays', 'today', 'tomorrow', 'yesterday', 'earlier', 'later', 'sooner', 'longer', 'shorter', 'better', 'worse', 'best', 'worst', 'greater', 'lesser', 'higher', 'lower', 'larger', 'smaller', 'bigger', 'littler', 'older', 'newer', 'younger', 'elder', 'latest', 'earliest', 'first', 'second', 'third', 'last', 'next', 'previous', 'following', 'preceding', 'subsequent', 'prior', 'former', 'latter', 'current', 'present', 'past', 'future', 'modern', 'ancient', 'recent', 'old', 'new', 'fresh', 'stale', 'original', 'copy', 'duplicate', 'unique', 'common', 'rare', 'unusual', 'typical', 'atypical', 'standard', 'nonstandard', 'regular', 'irregular', 'normal', 'abnormal', 'average', 'median', 'mean', 'mode', 'range', 'minimum', 'maximum', 'total', 'sum', 'difference', 'product', 'quotient', 'ratio', 'proportion', 'percentage', 'fraction', 'decimal', 'number', 'figure', 'digit', 'amount', 'quantity', 'volume', 'size', 'length', 'width', 'height', 'depth', 'area', 'perimeter', 'circumference', 'diameter', 'radius', 'angle', 'degree', 'temperature', 'pressure', 'weight', 'mass', 'density', 'speed', 'velocity', 'acceleration', 'force', 'energy', 'power', 'frequency', 'wavelength', 'amplitude', 'phase', 'period', 'cycle', 'rhythm', 'pattern', 'sequence', 'series', 'order', 'arrangement', 'organization', 'structure', 'system', 'method', 'process', 'procedure', 'technique', 'approach', 'strategy', 'plan', 'scheme', 'design', 'model', 'framework', 'concept', 'idea', 'notion', 'thought', 'opinion', 'view', 'perspective', 'viewpoint', 'standpoint', 'position', 'stance', 'attitude', 'belief', 'conviction', 'faith', 'trust', 'confidence', 'doubt', 'uncertainty', 'confusion', 'clarity', 'understanding', 'comprehension', 'knowledge', 'information', 'data', 'facts', 'details', 'specifics', 'particulars', 'features', 'characteristics', 'properties', 'qualities', 'attributes', 'aspects', 'elements', 'components', 'parts', 'pieces', 'sections', 'segments', 'portions', 'fractions', 'fragments', 'bits', 'chunks', 'blocks', 'units', 'items', 'objects', 'things', 'stuff', 'material', 'substance', 'matter', 'content', 'subject', 'topic', 'theme', 'issue', 'problem', 'question', 'answer', 'solution', 'result', 'outcome', 'consequence', 'effect', 'impact', 'influence', 'cause', 'reason', 'purpose', 'goal', 'objective', 'aim', 'target', 'intention', 'plan', 'desire', 'wish', 'want', 'need', 'requirement', 'demand', 'request', 'order', 'command', 'instruction', 'direction', 'guidance', 'advice', 'suggestion', 'recommendation', 'proposal', 'offer', 'invitation', 'welcome', 'greeting', 'farewell', 'goodbye', 'hello', 'hi', 'hey', 'yes', 'no', 'okay', 'alright', 'fine', 'good', 'great', 'excellent', 'wonderful', 'amazing', 'fantastic', 'incredible', 'unbelievable', 'impossible', 'possible', 'probable', 'likely', 'unlikely', 'certain', 'uncertain', 'sure', 'unsure', 'maybe', 'perhaps', 'possibly', 'definitely', 'absolutely', 'certainly', 'probably', 'apparently', 'obviously', 'clearly', 'evidently', 'supposedly', 'allegedly', 'reportedly', 'according', 'based', 'depending', 'regarding', 'concerning', 'involving', 'including', 'excluding', 'except', 'besides', 'apart', 'aside', 'along', 'across', 'through', 'throughout', 'within', 'without', 'against', 'towards', 'between', 'among', 'amongst', 'beyond', 'beneath', 'beside', 'behind', 'ahead', 'forward', 'backward', 'upward', 'downward', 'inward', 'outward', 'toward', 'away', 'together', 'apart', 'alone'}
        
        if text_data.strip():
            try:
                wordcloud = WordCloud(
                    width=800, 
                    height=400, 
                    background_color='white',
                    max_words=50,
                    stopwords=stop_words,
                    colormap='viridis'
                ).generate(text_data)
                
                fig_wc, ax = plt.subplots(figsize=(12, 6))
                ax.imshow(wordcloud, interpolation='bilinear')
                ax.axis('off')
                ax.set_title(f'Word Cloud: {selected_genre_wc}', fontsize=16, pad=20)
                
                st.pyplot(fig_wc)
                
            except Exception as e:
                st.warning("р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╕кр╕гр╣Йр╕▓р╕З Word Cloud р╣Др╕Фр╣Й р╕нр╕▓р╕Ир╣Ар╕Ыр╣Зр╕Щр╣Ар╕Юр╕гр╕▓р╕░р╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Др╕бр╣Ир╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕н")
        else:
            st.warning("р╣Др╕бр╣Ир╕бр╕╡р╕Вр╣Йр╕нр╕бр╕╣р╕е overview р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕ер╕╕р╣Ир╕бр╕Щр╕╡р╣Й")
    else:
        # Use keywords if available
        if 'micro_genre_keybert' in df.columns:
            # Extract only the selected genre keywords
            selected_keywords = []
            for genre_str in genre_movies['micro_genre_keybert'].dropna():
                genres = [g.strip() for g in str(genre_str).split('/')]
                if selected_genre_wc in genres:
                    selected_keywords.append(selected_genre_wc)
            
            keywords_data = ' '.join(selected_keywords)
            
            if keywords_data.strip():
                try:
                    # Enhanced stop words for keywords
                    keyword_stop_words = {'genre', 'micro', 'keybert', 'movie', 'film', 'cinema'}
                    
                    wordcloud = WordCloud(
                        width=800, 
                        height=400, 
                        background_color='white',
                        max_words=30,
                        colormap='plasma',
                        stopwords=keyword_stop_words
                    ).generate(keywords_data)
                    
                    fig_wc, ax = plt.subplots(figsize=(12, 6))
                    ax.imshow(wordcloud, interpolation='bilinear')
                    ax.axis('off')
                    ax.set_title(f'Keywords Cloud: {selected_genre_wc}', fontsize=16, pad=20)
                    
                    st.pyplot(fig_wc)
                    
                except Exception as e:
                    st.warning("р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╕кр╕гр╣Йр╕▓р╕З Word Cloud р╣Др╕Фр╣Й")
            else:
                st.warning("р╣Др╕бр╣Ир╕бр╕╡р╕Вр╣Йр╕нр╕бр╕╣р╕е keywords р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕ер╕╕р╣Ир╕бр╕Щр╕╡р╣Й")
        else:
            st.info("р╣Др╕бр╣Ир╕бр╕╡р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕кр╕│р╕лр╕гр╕▒р╕Ър╕кр╕гр╣Йр╕▓р╕З Word Cloud")
    
    # Statistics below the image
    st.markdown("#### ЁЯУК р╕кр╕Цр╕┤р╕Хр╕┤р╕Вр╕нр╕Зр╕Бр╕ер╕╕р╣Ир╕бр╕Щр╕╡р╣Й")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("р╕Ир╕│р╕Щр╕зр╕Щр╕лр╕Щр╕▒р╕З", len(genre_movies))
    
    with col2:
        if 'vote_average' in df.columns:
            avg_rating = genre_movies['vote_average'].mean()
            st.metric("р╕Др╕░р╣Бр╕Щр╕Щр╣Ар╕Йр╕ер╕╡р╣Ир╕в", f"{avg_rating:.1f}/10")
    
    with col3:
        if 'year' in df.columns:
            year_range = f"{genre_movies['year'].min():.0f} - {genre_movies['year'].max():.0f}"
            st.metric("р╕Кр╣Ир╕зр╕Зр╕Ыр╕╡", year_range)
    
    # Top movies in this genre
    if 'vote_average' in df.columns:
        st.markdown("**р╕лр╕Щр╕▒р╕Зр╕Др╕░р╣Бр╕Щр╕Щр╕кр╕╣р╕Зр╕кр╕╕р╕Ф:**")
        top_movies = genre_movies.nlargest(3, 'vote_average')[['title', 'vote_average']]
        for _, movie in top_movies.iterrows():
            st.write(f"тАв {movie['title']} ({movie['vote_average']:.1f})")

    st.info("""
    ЁЯТб **Insight:** Word Cloud р╕Кр╣Ир╕зр╕вр╕вр╕╖р╕Щр╕вр╕▒р╕Щр╕зр╣Ир╕▓р╕Чр╕│р╣Др╕б AI р╕Цр╕╢р╕Зр╕Ир╕▒р╕Фр╕Бр╕ер╕╕р╣Ир╕бр╕лр╕Щр╕▒р╕Зр╣Ар╕лр╕ер╣Ир╕▓р╕Щр╕╡р╣Йр╕бр╕▓р╕нр╕вр╕╣р╣Ир╕Фр╣Йр╕зр╕вр╕Бр╕▒р╕Щ 
    р╕Др╕│р╕Чр╕╡р╣Ир╕Ыр╕гр╕▓р╕Бр╕Пр╕Ър╣Ир╕нр╕вр╕Ир╕░р╕кр╕░р╕Чр╣Йр╕нр╕Щр╕Шр╕╡р╕б р╕нр╕▓р╕гр╕бр╕Ур╣М р╣Бр╕ер╕░р╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓р╕лр╕ер╕▒р╕Бр╕Вр╕нр╕З Micro-Genre р╕Щр╕▒р╣Йр╕Щр╣Ж
    """)

st.markdown("---")

# 3. Comparative Analysis
st.markdown("## ЁЯФм 3. р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Ар╕Кр╕┤р╕Зр╣Ар╕Ыр╕гр╕╡р╕вр╕Ър╣Ар╕Чр╕╡р╕вр╕Ъ")

st.markdown("### ЁЯУК Scatter Plot: р╕Ыр╕╡ vs р╕Др╕░р╣Бр╕Щр╕Щ vs Micro-Genre")

if 'vote_average' in df.columns:
    # Sample data for better performance if dataset is large
    sample_size = min(1000, len(df))
    df_sample = df.sample(n=sample_size, random_state=42)
    
    # Get top 8 genres for color coding
    top_8_genres = df['micro_genre_keybert'].value_counts().head(8).index
    df_sample_filtered = df_sample[df_sample['micro_genre_keybert'].isin(top_8_genres)]
    
    fig_scatter = px.scatter(
        df_sample_filtered,
        x='year',
        y='vote_average',
        color='micro_genre_keybert',
        title=f"р╕Бр╕▓р╕гр╕Бр╕гр╕░р╕Ир╕▓р╕вр╕Хр╕▒р╕зр╕Вр╕нр╕Зр╕лр╕Щр╕▒р╕З: р╕Ыр╕╡ vs р╕Др╕░р╣Бр╕Щр╕Щ (р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕З {len(df_sample_filtered)} р╣Ар╕гр╕╖р╣Ир╕нр╕З)",
        labels={'year': 'р╕Ыр╕╡р╕Чр╕╡р╣Ир╕Йр╕▓р╕в', 'vote_average': 'р╕Др╕░р╣Бр╕Щр╕Щ IMDB', 'micro_genre_keybert': 'Micro-Genre'},
        hover_data=['title'] if 'title' in df.columns else None,
        opacity=0.7
    )
    
    fig_scatter.update_layout(
        height=500,
        legend=dict(
            orientation="v",
            yanchor="top",
            y=1,
            xanchor="left",
            x=1.02
        )
    )
    
    st.plotly_chart(fig_scatter, use_container_width=True)
    
    st.info("""
    ЁЯТб **Insight:** р╕Бр╕гр╕▓р╕Яр╕Ир╕╕р╕Фр╣Бр╕кр╕Фр╕Зр╣Гр╕лр╣Йр╣Ар╕лр╣Зр╕Щ "Cluster" р╕Вр╕нр╕Зр╣Бр╕Хр╣Ир╕ер╕░ Micro-Genre 
    - **р╣Бр╕Бр╕Щ X (р╕Ыр╕╡):** р╕Ър╕▓р╕Зр╕Бр╕ер╕╕р╣Ир╕бр╕нр╕▓р╕Ир╕Бр╕гр╕░р╕Ир╕╕р╕Бр╕Хр╕▒р╕зр╣Гр╕Щр╕вр╕╕р╕Др╣Гр╕Фр╕вр╕╕р╕Др╕лр╕Щр╕╢р╣Ир╕З
    - **р╣Бр╕Бр╕Щ Y (р╕Др╕░р╣Бр╕Щр╕Щ):** р╕Ър╕▓р╕Зр╕Бр╕ер╕╕р╣Ир╕бр╕нр╕▓р╕Ир╕бр╕╡р╕Др╕╕р╕Ур╕ар╕▓р╕Юр╕кр╕бр╣Ир╕│р╣Ар╕кр╕бр╕нр╕кр╕╣р╕З/р╕Хр╣Ир╕│
    - **р╕кр╕╡:** р╣Бр╕вр╕Бр╣Бр╕вр╕░ Micro-Genre р╕Хр╣Ир╕▓р╕Зр╣Ж
    """)
    
    # Genre performance over time
    st.markdown("### ЁЯУИ р╕Ыр╕гр╕░р╕кр╕┤р╕Чр╕Шр╕┤р╕ар╕▓р╕Юр╕Вр╕нр╕З Micro-Genres р╕Хр╕▓р╕бр╣Ар╕зр╕ер╕▓")
    
    # Calculate average rating by decade for top genres
    df_decade = df.copy()
    df_decade['decade'] = (df_decade['year'] // 10) * 10
    
    decade_performance = df_decade[df_decade['micro_genre_keybert'].isin(top_8_genres)].groupby(['decade', 'micro_genre_keybert'])['vote_average'].mean().reset_index()
    
    fig_performance = px.line(
        decade_performance,
        x='decade',
        y='vote_average',
        color='micro_genre_keybert',
        title="р╕Др╕░р╣Бр╕Щр╕Щр╣Ар╕Йр╕ер╕╡р╣Ир╕вр╕Вр╕нр╕З Micro-Genres р╣Гр╕Щр╣Бр╕Хр╣Ир╕ер╕░р╕Чр╕ир╕зр╕гр╕гр╕й",
        labels={'decade': 'р╕Чр╕ир╕зр╕гр╕гр╕й', 'vote_average': 'р╕Др╕░р╣Бр╕Щр╕Щр╣Ар╕Йр╕ер╕╡р╣Ир╕в', 'micro_genre_keybert': 'Micro-Genre'},
        markers=True
    )
    
    fig_performance.update_layout(height=400)
    st.plotly_chart(fig_performance, use_container_width=True)

else:
    st.warning("р╣Др╕бр╣Ир╕бр╕╡р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Др╕░р╣Бр╕Щр╕Щр╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Ар╕Кр╕┤р╕Зр╣Ар╕Ыр╕гр╕╡р╕вр╕Ър╣Ар╕Чр╕╡р╕вр╕Ъ")

# Summary Statistics
st.markdown("---")
st.markdown("## ЁЯУЛ р╕кр╕гр╕╕р╕Ыр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Кр╕┤р╕Зр╕ер╕╢р╕Б")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("#### ЁЯОп Micro-Genre р╕Чр╕╡р╣Ир╣Вр╕Фр╕Фр╣Ар╕Фр╣Ир╕Щ")
    
    # Most consistent genre (lowest std deviation in ratings)
    if 'vote_average' in df.columns:
        genre_consistency = df.groupby('micro_genre_keybert')['vote_average'].agg(['mean', 'std', 'count']).reset_index()
        genre_consistency = genre_consistency[genre_consistency['count'] >= 5]  # At least 5 movies
        most_consistent = genre_consistency.loc[genre_consistency['std'].idxmin()]
        
        st.write(f"**р╕Др╕╕р╕Ур╕ар╕▓р╕Юр╕кр╕бр╣Ир╕│р╣Ар╕кр╕бр╕н:** {most_consistent['micro_genre_keybert']}")
        st.write(f"р╕Др╕░р╣Бр╕Щр╕Щр╣Ар╕Йр╕ер╕╡р╣Ир╕в: {most_consistent['mean']:.1f} (┬▒{most_consistent['std']:.1f})")

with col2:
    st.markdown("#### ЁЯУЕ р╣Ар╕Чр╕гр╕Щр╕Фр╣Мр╕Хр╕▓р╕бр╣Ар╕зр╕ер╕▓")
    
    # Fastest growing genre in recent years
    recent_years = df[df['year'] >= 2010]
    if len(recent_years) > 0:
        recent_growth = recent_years['micro_genre_keybert'].value_counts().head(1)
        st.write(f"**р╣Ар╕Хр╕┤р╕Ър╣Вр╕Хр╣Ар╕гр╣Зр╕зр╕кр╕╕р╕Ф (2010+):** {recent_growth.index[0]}")
        st.write(f"р╕Ир╕│р╕Щр╕зр╕Щ: {recent_growth.iloc[0]} р╣Ар╕гр╕╖р╣Ир╕нр╕З")

with col3:
    st.markdown("#### ЁЯПЖ р╕Др╕зр╕▓р╕бр╕лр╕ер╕▓р╕Бр╕лр╕ер╕▓р╕в")
    
    # Genre diversity index
    total_genres = df['micro_genre_keybert'].nunique()
    movies_per_genre = len(df) / total_genres
    
    st.write(f"**р╕Фр╕▒р╕Кр╕Щр╕╡р╕Др╕зр╕▓р╕бр╕лр╕ер╕▓р╕Бр╕лр╕ер╕▓р╕в:** {total_genres} р╕Бр╕ер╕╕р╣Ир╕б")
    st.write(f"р╣Ар╕Йр╕ер╕╡р╣Ир╕в: {movies_per_genre:.1f} р╣Ар╕гр╕╖р╣Ир╕нр╕З/р╕Бр╕ер╕╕р╣Ир╕б")

# Navigation
st.markdown("---")
st.markdown("""
### ЁЯзн р╕кр╕│р╕гр╕зр╕Ир╕Хр╣Ир╕н

ЁЯОм **р╕ер╕нр╕Зр╣Др╕Ыр╕лр╕▓р╕лр╕Щр╕▒р╕Зр╕Чр╕╡р╣Ир╕Кр╕нр╕Ъ:** р╣Гр╕Кр╣Йр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕╡р╣Ир╣Др╕Фр╣Йр╕Ир╕▓р╕Бр╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Щр╕╡р╣Йр╣Др╕Ыр╕Др╣Йр╕Щр╕лр╕▓р╣Гр╕Щр╕лр╕Щр╣Йр╕▓ **Explorer**

ЁЯУК **р╕Фр╕╣р╕ар╕▓р╕Юр╕гр╕зр╕б:** р╕Бр╕ер╕▒р╕Ър╣Др╕Ыр╕Фр╕╣р╕кр╕Цр╕┤р╕Хр╕┤р╣Вр╕Фр╕вр╕гр╕зр╕бр╣Гр╕Щр╕лр╕Щр╣Йр╕▓ **Overview**
""")